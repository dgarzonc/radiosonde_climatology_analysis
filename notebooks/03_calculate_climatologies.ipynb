{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9833a219-9163-4b65-bf51-59f193166fd1",
   "metadata": {},
   "source": [
    "<h1> Climatological calculations from sounding data</h1>\n",
    "<br>\n",
    "\n",
    "This notebook computes daily climatological means from processed IGRA2 radiosonde data, creating a comprehensive atmospheric reference dataset for each day of the year. Using interpolated pressure-level data from individual soundings, the analysis generates climatological profiles that capture the typical atmospheric structure and variability patterns throughout the annual cycle.\n",
    "#### Methodology\n",
    "The climatological calculation employs a moving window approach to compute daily means, where each day of the year incorporates soundings from a specified temporal window (typically ±15 days) across all available years. This method ensures statistical robustness while preserving the seasonal signal in atmospheric variables. For each day, the process calculates ensemble means of fundamental atmospheric parameters (temperature, humidity, wind) and derives additional meteorological diagnostics including thermodynamic variables (potential temperature, equivalent potential temperature) and energy-related quantities (air density, wind power density).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cfbb0a-1408-44da-b2fe-a64dec67adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the parameters in this cell according to your requirements\n",
    "\n",
    "# ID of selected station\n",
    "ID = 'COM00080222'\n",
    "\n",
    "# Period of climatology\n",
    "clim_start_year = 1991\n",
    "clim_end_year = 2020\n",
    "clim_hour = 12  # UTC hour of sonde release\n",
    "\n",
    "# Path of the repository folder\n",
    "path_repo = '/home/david/radiosonde_climatology_analysis/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1714f-dcc4-4901-af79-27b4a52a35cd",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a4889-3f80-4f18-b822-f5c1c0c73de7",
   "metadata": {},
   "source": [
    "# 0. Preamble (functions and libs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37c822a-232f-42d1-9106-552ee2ab6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "### folders' paths\n",
    "\n",
    "docs_folder = f'{path_repo}/docs/'\n",
    "station_folder = f'{path_repo}/data/{ID}/'\n",
    "interpolated_folder = f'{station_folder}/interpolated/'\n",
    "climatologies_folder = f'{station_folder}/climatology/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b0d07d-bb89-49e5-9df1-6676f3af6875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from metpy import calc as mpcalc\n",
    "from metpy.units import units\n",
    "\n",
    "def print_(str_to_print):\n",
    "   datetime_now = datetime.now()\n",
    "   print(datetime_now.strftime('[%Y-%m-%d %H:%M:%S]: ')+str_to_print)\n",
    "\n",
    "def calculate_relative_humidity(temp, dew):\n",
    "   temp = temp * units.degC\n",
    "   dew = dew * units.degC    \n",
    "   rh = mpcalc.relative_humidity_from_dewpoint(temp, dew)    \n",
    "   rh = rh.magnitude * 100    \n",
    "   return rh\n",
    "\n",
    "def calculate_dewpoint(temp, rh):\n",
    "   temp = temp * units.degC\n",
    "   rh = rh * units.percent    \n",
    "   dew = mpcalc.dewpoint_from_relative_humidity(temp, rh).to(units.degC)    \n",
    "   dew = dew.magnitude\n",
    "   return dew\n",
    "\n",
    "def calculate_vapor_pressure(press, temp, dew):\n",
    "   dew = dew * units.degC   \n",
    "   temp = temp * units.degC\n",
    "   press = press * units.hPa\n",
    "   e = mpcalc.psychrometric_vapor_pressure_wet(press, temp, dew)    \n",
    "   return e\n",
    "\n",
    "def calculate_specific_humidity(press, dew):\n",
    "   dew = dew * units.degC   \n",
    "   press = press * units.hPa\n",
    "   q = mpcalc.specific_humidity_from_dewpoint(press, dew).to('g/kg')  \n",
    "   return q\n",
    "\n",
    "def calculate_equivalent_potential_temperature(press, temp, dew):\n",
    "   dew = dew * units.degC   \n",
    "   temp = temp * units.degC\n",
    "   press = press * units.hPa\n",
    "   ept = mpcalc.equivalent_potential_temperature(press, temp, dew).to(units.degC)  \n",
    "   return ept\n",
    "\n",
    "def calculate_potential_temperature(press, temp):\n",
    "   temp = temp * units.degC\n",
    "   press = press * units.hPa\n",
    "   pt = mpcalc.potential_temperature(press, temp).to(units.degC)  \n",
    "   return pt\n",
    "\n",
    "def calculate_wind_speed(u, v):\n",
    "   return (u**2+v**2)**0.5\n",
    "\n",
    "def calculate_air_density(press, temp, rh):\n",
    "   return (press* 0.02897) / (8.31446*(1+(0.66*(rh/100.)*(temp+273.15)))) \n",
    "\n",
    "def calculate_air_density(press, temp, rh):\n",
    "   temp = temp * units.degC\n",
    "   press = press * units.hPa\n",
    "   rh = rh /100. # relative humidity base 1\n",
    "   mixing_ratio = mpcalc.mixing_ratio_from_relative_humidity(press, temp, rh).to('g/kg')\n",
    "   rho = mpcalc.density(press, temp, mixing_ratio)\n",
    "   return rho\n",
    "\n",
    "def calculate_wind_power_density(rho, speed):\n",
    "   return 0.5*rho*(speed**3)\n",
    "\n",
    "############\n",
    "### Creating the station's folders\n",
    "os.makedirs(climatologies_folder, exist_ok = True)\n",
    "os.makedirs(f'{climatologies_folder}/daily_mean', exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe56489-9782-4e94-9df2-10e16d00e8e7",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d5de6-699e-45b1-ad67-8430b5129c0c",
   "metadata": {},
   "source": [
    "# 1. Calculation of daily mean profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83718e5c-90b2-4c0a-82ed-9d5a994d4a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADREC</th>\n",
       "      <th>ID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>RELTIME</th>\n",
       "      <th>NUMLEV</th>\n",
       "      <th>P_SRC</th>\n",
       "      <th>NP_SRC</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DATETIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9999</td>\n",
       "      <td>40</td>\n",
       "      <td>ncdc6322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>1991-01-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>9999</td>\n",
       "      <td>34</td>\n",
       "      <td>ncdc6322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>1991-01-02 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9999</td>\n",
       "      <td>37</td>\n",
       "      <td>usaf-ds3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>1991-01-04 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9999</td>\n",
       "      <td>28</td>\n",
       "      <td>ncdc6322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>1991-01-05 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>9999</td>\n",
       "      <td>28</td>\n",
       "      <td>ncdc6322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>1991-01-06 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>1139</td>\n",
       "      <td>179</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>2020-12-27 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9162</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>1137</td>\n",
       "      <td>173</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>2020-12-28 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9163</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>1134</td>\n",
       "      <td>156</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>2020-12-29 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1131</td>\n",
       "      <td>126</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>2020-12-30 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9167</th>\n",
       "      <td>#</td>\n",
       "      <td>COM00080222</td>\n",
       "      <td>2020</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1139</td>\n",
       "      <td>176</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>ncdc-gts</td>\n",
       "      <td>47000</td>\n",
       "      <td>-741500</td>\n",
       "      <td>2020-12-31 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8630 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HEADREC           ID  YEAR  MONTH  DAY  HOUR  RELTIME  NUMLEV     P_SRC  \\\n",
       "1          #  COM00080222  1991      1    1    12     9999      40  ncdc6322   \n",
       "3          #  COM00080222  1991      1    2    12     9999      34  ncdc6322   \n",
       "6          #  COM00080222  1991      1    4    12     9999      37  usaf-ds3   \n",
       "8          #  COM00080222  1991      1    5    12     9999      28  ncdc6322   \n",
       "9          #  COM00080222  1991      1    6    12     9999      28  ncdc6322   \n",
       "...      ...          ...   ...    ...  ...   ...      ...     ...       ...   \n",
       "9161       #  COM00080222  2020     12   27    12     1139     179  ncdc-gts   \n",
       "9162       #  COM00080222  2020     12   28    12     1137     173  ncdc-gts   \n",
       "9163       #  COM00080222  2020     12   29    12     1134     156  ncdc-gts   \n",
       "9165       #  COM00080222  2020     12   30    12     1131     126  ncdc-gts   \n",
       "9167       #  COM00080222  2020     12   31    12     1139     176  ncdc-gts   \n",
       "\n",
       "        NP_SRC    LAT     LON            DATETIME  \n",
       "1          NaN  47000 -741500 1991-01-01 12:00:00  \n",
       "3          NaN  47000 -741500 1991-01-02 12:00:00  \n",
       "6          NaN  47000 -741500 1991-01-04 12:00:00  \n",
       "8          NaN  47000 -741500 1991-01-05 12:00:00  \n",
       "9          NaN  47000 -741500 1991-01-06 12:00:00  \n",
       "...        ...    ...     ...                 ...  \n",
       "9161  ncdc-gts  47000 -741500 2020-12-27 12:00:00  \n",
       "9162  ncdc-gts  47000 -741500 2020-12-28 12:00:00  \n",
       "9163  ncdc-gts  47000 -741500 2020-12-29 12:00:00  \n",
       "9165  ncdc-gts  47000 -741500 2020-12-30 12:00:00  \n",
       "9167  ncdc-gts  47000 -741500 2020-12-31 12:00:00  \n",
       "\n",
       "[8630 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sondes = pd.read_csv(f'{interpolated_folder}/{ID}__availability.csv')\n",
    "df_sondes = df_sondes.loc[(df_sondes['YEAR']>=clim_start_year)&(df_sondes['YEAR']<=clim_end_year)]\n",
    "df_sondes = df_sondes.loc[df_sondes['HOUR']==clim_hour]\n",
    "df_sondes['DATETIME'] = pd.to_datetime(df_sondes[['YEAR', 'MONTH', 'DAY', 'HOUR']])\n",
    "df_sondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838dd1fc-90f9-47a4-a8c5-40fe2c37800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 11:34:30]: Calculating daily climatological means for COM00080222\n",
      "[2025-07-28 11:34:30]: It could take several minutes...\n",
      "[2025-07-28 11:34:30]: Pre-loading sounding data...\n",
      "[2025-07-28 11:34:30]: Found 9168 available sounding files\n",
      "[2025-07-28 11:34:30]: Filtered to 8630 soundings within climatology period\n",
      "[2025-07-28 11:34:56]: Progress: 10% (37/365 days)\n",
      "[2025-07-28 11:35:22]: Progress: 20% (73/365 days)\n",
      "[2025-07-28 11:35:48]: Progress: 30% (110/365 days)\n",
      "[2025-07-28 11:36:14]: Progress: 40% (146/365 days)\n",
      "[2025-07-28 11:36:42]: Progress: 50% (183/365 days)\n",
      "[2025-07-28 11:37:09]: Progress: 60% (219/365 days)\n",
      "[2025-07-28 11:37:36]: Progress: 70% (256/365 days)\n",
      "[2025-07-28 11:38:02]: Progress: 80% (292/365 days)\n",
      "[2025-07-28 11:38:30]: Progress: 90% (329/365 days)\n",
      "[2025-07-28 11:38:58]: Progress: 100% (365/365 days)\n",
      "[2025-07-28 11:38:58]: Climatological daily means calculation completed for COM00080222\n"
     ]
    }
   ],
   "source": [
    "print_(f'Calculating daily climatological means for {ID}')\n",
    "print_('It could take several minutes...')\n",
    "\n",
    "# Moving window approach to compute daily means\n",
    "window = 15  # days\n",
    "\n",
    "# Review of available days\n",
    "datetime_start_i = datetime(clim_start_year, 1, 1, 12)\n",
    "datetime_end_i = datetime(clim_end_year, 12, 31, 12)\n",
    "\n",
    "# Pre-load all sounding files into memory (if feasible) or create a file cache\n",
    "print_('Pre-loading sounding data...')\n",
    "sounding_cache = {}\n",
    "available_files = set()\n",
    "\n",
    "# Get list of available files\n",
    "import glob\n",
    "available_file_paths = glob.glob(f'{interpolated_folder}/{ID}_*.csv')\n",
    "for file_path in available_file_paths:\n",
    "    filename = os.path.basename(file_path)\n",
    "    file_date_str = filename.split('_')[1].replace('.csv', '')\n",
    "    try:\n",
    "        file_date = datetime.strptime(file_date_str, '%Y%m%d%H%M')\n",
    "        available_files.add(file_date)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print_(f'Found {len(available_files)} available sounding files')\n",
    "\n",
    "# Pre-filter df_sondes to only include dates within our climatology period\n",
    "df_sondes_filtered = df_sondes[\n",
    "    (df_sondes['DATETIME'] >= datetime_start_i) & \n",
    "    (df_sondes['DATETIME'] <= datetime_end_i) & \n",
    "    (df_sondes['DATETIME'].isin(available_files))\n",
    "].copy()\n",
    "\n",
    "print_(f'Filtered to {len(df_sondes_filtered)} soundings within climatology period')\n",
    "\n",
    "# Function to calculate derived variables from means\n",
    "def calculate_derived_from_means(df_means):\n",
    "    \"\"\"Calculate derived atmospheric variables from climatological means\"\"\"\n",
    "    # Calculate derived variables from the averaged primary variables\n",
    "    df_means['dewpoint_temperature'] = calculate_dewpoint(df_means['temperature'].values, df_means['relative_humidity'].values)\n",
    "    df_means['vapor_pressure'] = calculate_vapor_pressure(df_means['pressure'].values, df_means['temperature'].values, df_means['dewpoint_temperature'].values)\n",
    "    df_means['specific_humidity'] = calculate_specific_humidity(df_means['pressure'].values, df_means['dewpoint_temperature'].values)\n",
    "    df_means['equivalent_potential_temperature'] = calculate_equivalent_potential_temperature(df_means['pressure'].values, df_means['temperature'].values, df_means['dewpoint_temperature'].values)\n",
    "    df_means['potential_temperature'] = calculate_potential_temperature(df_means['pressure'].values, df_means['temperature'].values)\n",
    "    df_means['wind_speed'] = calculate_wind_speed(df_means['u_wind'].values, df_means['v_wind'].values)\n",
    "    df_means['air_density'] = calculate_air_density(df_means['pressure'].values, df_means['temperature'].values, df_means['relative_humidity'].values)\n",
    "    df_means['wind_power_density'] = calculate_wind_power_density(df_means['air_density'].values, df_means['wind_speed'].values)\n",
    "    return df_means\n",
    "\n",
    "# Batch process soundings for efficiency (only primary variables)\n",
    "def process_soundings_batch(file_list, batch_size=50):\n",
    "    \"\"\"Process multiple soundings in batches - primary variables only\"\"\"\n",
    "    all_soundings = []\n",
    "    \n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        batch_files = file_list[i:i+batch_size]\n",
    "        batch_dfs = []\n",
    "        \n",
    "        # Read batch of files\n",
    "        for filename in batch_files:\n",
    "            try:\n",
    "                df_temp = pd.read_csv(f'{interpolated_folder}/{filename}')\n",
    "                # Rename columns and keep only primary variables\n",
    "                df_temp = df_temp.rename(columns={\n",
    "                    'PRESS': 'pressure',\n",
    "                    'GPH': 'geopotential_height', \n",
    "                    'TEMP': 'temperature',\n",
    "                    'RH': 'relative_humidity',\n",
    "                    'U': 'u_wind',\n",
    "                    'V': 'v_wind'\n",
    "                })\n",
    "                # Keep only primary variables for averaging\n",
    "                primary_vars = ['pressure', 'geopotential_height', 'temperature', 'relative_humidity', 'u_wind', 'v_wind']\n",
    "                df_temp = df_temp[primary_vars]\n",
    "                batch_dfs.append(df_temp)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if batch_dfs:\n",
    "            # Concatenate batch (no derived calculations yet)\n",
    "            batch_combined = pd.concat(batch_dfs, ignore_index=True)\n",
    "            all_soundings.append(batch_combined)\n",
    "    \n",
    "    return pd.concat(all_soundings, ignore_index=True) if all_soundings else pd.DataFrame()\n",
    "\n",
    "# Initialize progress tracking variables\n",
    "total_days = 365\n",
    "completed_days = 0\n",
    "last_printed_percentage = 0\n",
    "\n",
    "# Standard pressure levels\n",
    "standard_pressures = list(range(1010, 95, -5))\n",
    "column_names = ['pressure', 'geopotential_height', 'temperature', 'relative_humidity', 'u_wind', 'v_wind', \n",
    "                'dewpoint_temperature', 'vapor_pressure', 'specific_humidity', 'equivalent_potential_temperature', \n",
    "                'potential_temperature', 'wind_speed', 'air_density', 'wind_power_density']\n",
    "\n",
    "for dayofyear_i in range(1, 366):  # Include day 365\n",
    "    # Select soundings for the climatological mean for that day of year\n",
    "    target_dates = []\n",
    "    for year_i in range(datetime_start_i.year, datetime_end_i.year + 1):\n",
    "        base_date = datetime(year_i, 1, 1) + timedelta(days=dayofyear_i - 1, hours=clim_hour)\n",
    "        window_dates = [base_date + timedelta(days=dt) for dt in range(-window, window)]\n",
    "        target_dates.extend(window_dates)\n",
    "    \n",
    "    # Filter available soundings for this day of year (much faster with pre-filtered data)\n",
    "    df_sondes_date_i = df_sondes_filtered[df_sondes_filtered['DATETIME'].isin(target_dates)]\n",
    "    \n",
    "    # Check available information\n",
    "    # At least 40% of the data. I set this threshold for greater flexibility, but feel free to adjust it if you consider it necessary\n",
    "    if len(df_sondes_date_i) < len(target_dates) * 0.4:\n",
    "        print_(f'Not enough information available for day of year {dayofyear_i:03d}.')\n",
    "        # Export blank dataframe\n",
    "        df_mean_i = pd.DataFrame(columns=column_names)\n",
    "        for press_i in standard_pressures:\n",
    "            df_mean_i.loc[len(df_mean_i), 'pressure'] = press_i\n",
    "        df_mean_i.to_csv(f'{climatologies_folder}/daily_mean/soundingmean_day_{dayofyear_i:03d}.csv', index=False)\n",
    "        \n",
    "        # Update progress\n",
    "        completed_days += 1\n",
    "        current_percentage = (completed_days * 100) // total_days\n",
    "        if current_percentage >= last_printed_percentage + 10 and current_percentage <= 100:\n",
    "            print_(f'Progress: {current_percentage}% ({completed_days}/{total_days} days)')\n",
    "            last_printed_percentage = current_percentage\n",
    "        continue\n",
    "    \n",
    "    # Create list of filenames to process\n",
    "    file_list = []\n",
    "    for _, row in df_sondes_date_i.iterrows():\n",
    "        filename = f'{ID}_{row[\"DATETIME\"].strftime(\"%Y%m%d%H%M\")}.csv'\n",
    "        file_list.append(filename)\n",
    "    \n",
    "    # Process soundings in batches (primary variables only)\n",
    "    df_combined = process_soundings_batch(file_list)\n",
    "    \n",
    "    if df_combined.empty:\n",
    "        print_(f'No valid data processed for day of year {dayofyear_i:03d}.')\n",
    "        # Export blank dataframe\n",
    "        df_mean_i = pd.DataFrame(columns=column_names)\n",
    "        for press_i in standard_pressures:\n",
    "            df_mean_i.loc[len(df_mean_i), 'pressure'] = press_i\n",
    "        df_mean_i.to_csv(f'{climatologies_folder}/daily_mean/soundingmean_day_{dayofyear_i:03d}.csv', index=False)\n",
    "    else:\n",
    "        # Calculate climatological means for primary variables only\n",
    "        primary_columns = ['geopotential_height', 'temperature', 'relative_humidity', 'u_wind', 'v_wind']\n",
    "        df_mean_i = df_combined.groupby('pressure')[primary_columns].mean().reset_index()\n",
    "        df_mean_i = df_mean_i.sort_values('pressure', ascending=False)\n",
    "        \n",
    "        # Now calculate derived variables from the means\n",
    "        df_mean_i = calculate_derived_from_means(df_mean_i)\n",
    "        \n",
    "        df_mean_i.to_csv(f'{climatologies_folder}/daily_mean/soundingmean_day_{dayofyear_i:03d}.csv', index=False)\n",
    "    \n",
    "    # Update progress\n",
    "    completed_days += 1\n",
    "    current_percentage = (completed_days * 100) // total_days\n",
    "    if current_percentage >= last_printed_percentage + 10 and current_percentage <= 100:\n",
    "        print_(f'Progress: {current_percentage}% ({completed_days}/{total_days} days)')\n",
    "        last_printed_percentage = current_percentage\n",
    "\n",
    "print_(f'Climatological daily means calculation completed for {ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14a5d4-8fea-43cf-8c0f-aff67d5782a1",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4036da-76d0-432e-a724-8f2ad6fc2990",
   "metadata": {},
   "source": [
    "# 2. Annual cycle dataset arrangement\n",
    "This section rearranges the daily climatological means into variable-specific annual cycle datasets where each row represents a pressure level and each column represents a day of the year (1-365). This format facilitates analysis of seasonal patterns, annual cycles, and temporal variability for each atmospheric variable throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db41fab-c703-47a9-b2c7-53cea3dd6d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 11:39:03]: Annual cycle datasets arranged for all variables at COM00080222\n"
     ]
    }
   ],
   "source": [
    "variables = ['geopotential_height', 'temperature', 'relative_humidity',\n",
    "             'u_wind', 'v_wind', 'dewpoint_temperature', 'vapor_pressure',\n",
    "             'specific_humidity', 'equivalent_potential_temperature',\n",
    "             'potential_temperature', 'wind_speed', 'air_density',\n",
    "             'wind_power_density']\n",
    "\n",
    "for variable in variables:\n",
    "    # Pre-load all daily mean files once\n",
    "    daily_data = {}\n",
    "    for dayofyear_i in range(1, 366):\n",
    "        df_mean_i = pd.read_csv(f'{climatologies_folder}/daily_mean/soundingmean_day_{dayofyear_i:03d}.csv')\n",
    "        daily_data[dayofyear_i] = df_mean_i[variable]\n",
    "    \n",
    "    # Create DataFrame with all columns at once\n",
    "    df_var = pd.DataFrame(daily_data)\n",
    "    df_var.insert(0, 'pressure', list(range(1010, 95, -5)))\n",
    "    \n",
    "    df_var.to_csv(f'{climatologies_folder}/{variable}.csv', index=False)\n",
    "\n",
    "print_(f'Annual cycle datasets arranged for all variables at {ID}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
